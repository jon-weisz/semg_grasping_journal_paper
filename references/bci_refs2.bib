@article{Ahmadi2009,
annote = {Relevance 3
        
Device:
256 Positions
F3 F4 C3 C4 
International 10-20
        
Control Type
2-Class classifier
Switch type 
        
Processing:
Neural Network
Log Linearized Gaussian Mixture Network
Ocular Artifact Suppression
        
        
Task:
Static
Hand Open/Close
Grasping
        
Success Rate:
73-91\%
        
      },
author = {Ahmadi, Mohammad and Erfanian, Abbas},
journal = {Science And Technology},
pages = {367--370},
title = {{An On-Line BCI System for Hand Movement Control Using Real-Time Recurrent Probabilistic Neural Network}},
year = {2009}
}
@article{Artemiadis2010,
abstract = {As robots come closer to humans, an efficient human-robot-control interface is an utmost necessity. In this paper, electromyographic (EMG) signals from muscles of the human upper limb are used as the control interface between the user and a robot arm. A mathematical model is trained to decode upper limb motion from EMG recordings, using a dimensionality-reduction technique that represents muscle synergies and motion primitives. It is shown that a 2-D embedding of muscle activations can be decoded to a continuous profile of arm motion representation in the 3-D Cartesian space, embedded in a 2-D space. The system is used for the continuous control of a robot arm, using only EMG signals from the upper limb. The accuracy of the method is assessed through real-time experiments, including random arm motions.},
author = {Artemiadis, P.K. and Kyriakopoulos, K.J.},
journal = {IEEE Transactions on Robotics},
month = apr,
number = {2},
pages = {393--398},
title = {{EMG-Based Control of a Robot Arm Using Low-Dimensional Embeddings}},
volume = {26},
year = {2010}
}
@article{Artemiadis2011,
abstract = {Human-robot control interfaces have received increased attention during the last decades. These interfaces increasingly use signals coming directly from humans since there is a strong necessity for simple and natural control interfaces. In this paper, electromyographic (EMG) signals from the muscles of the human upper limb are used as the control interface between the user and a robot arm. A switching regime model is used to decode the EMG activity of 11 muscles to a continuous representation of arm motion in the 3-D space. The switching regime model is used to overcome the main difficulties of the EMG-based control systems, i.e., the nonlinearity of the relationship between the EMG recordings and the arm motion, as well as the nonstationarity of EMG signals with respect to time. The proposed interface allows the user to control in real time an anthropomorphic robot arm in the 3-D space. The efficiency of the method is assessed through real-time experiments of four persons performing random arm motions.},
author = {Artemiadis, Panagiotis K and Kyriakopoulos, Kostas J},
journal = {IEEE Trans. on Systems, Man, and Cybernetics},
month = feb,
number = {1},
pages = {53--63},
title = {{A switching regime model for the EMG-based control of a robot arm.}},
volume = {41},
year = {2011}
}
@article{BarretoA.B.ScargleS.D.&Adjouadi2000,
author = {Barreto, A.B. and Scargle, S.D. and Adjouadi, M.},
journal = {Journal of Rehabilitation Research and Development},
number = {1},
pages = {53--63},
title = {{A practical EMG-based human-computer interface for users with motor disabilities}},
volume = {37},
year = {2000}
}
@article{Bell2008,
abstract = {We describe a brain-computer interface for controlling a humanoid robot directly using brain signals obtained non-invasively from the scalp through electroencephalography (EEG). EEG has previously been used for tasks such as controlling a cursor and spelling a word, but it has been regarded as an unlikely candidate for more complex forms of control owing to its low signal-to-noise ratio. Here we show that by leveraging advances in robotics, an interface based on EEG can be used to command a partially autonomous humanoid robot to perform complex tasks such as walking to specific locations and picking up desired objects. Visual feedback from the robot's cameras allows the user to select arbitrary objects in the environment for pick-up and transport to chosen locations. Results from a study involving nine users indicate that a command for the robot can be selected from four possible choices in 5 s with 95\% accuracy. Our results demonstrate that an EEG-based brain-computer interface can be used for sophisticated robotic interaction with the environment, involving not only navigation as in previous applications but also manipulation and transport of objects.},
author = {Bell, Christian J and Shenoy, Pradeep and Chalodhorn, Rawichote and Rao, Rajesh},
journal = {Journal of Neural Engineering},
month = {Jun},
number = {2},
pages = {214--20},
title = {{Control of a humanoid robot by a noninvasive brain-computer interface in humans.}},
volume = {5},
year = {2008}
}
@inproceedings{Bergamasco2011,
abstract = {This paper presents the preliminary results of the project BRAVO (Brain computer interfaces for Robotic enhanced Action in Visuo-motOr tasks). The objective of this project is to define a new approach to the development of assistive and rehabilitative robots for motor impaired users to perform complex visuomotor tasks that require a sequence of reaches, grasps and manipulations of objects. BRAVO aims at developing new robotic interfaces and HW/SW architectures for rehabilitation and regain/restoration of motor function in patients with upper limb sensorimotor impairment through extensive rehabilitation therapy and active assistance in the execution of Activities of Daily Living. The final system developed within this project will include a robotic arm exoskeleton and a hand orthosis that will be integrated together for providing force assistance. The main novelty that BRAVO introduces is the control of the robotic assistive device through the active prediction of intention/action. The system will actually integrate the information about the movement carried out by the user with a prediction of the performed action through an interpretation of current gaze of the user (measured through eye-tracking), brain activation (measured through BCI) and force sensor measurements.},
author = {Bergamasco, Massimo and Frisoli, Antonio and Fontana, Marco and Loconsole, Claudio and Leonardis, Daniele and Troncossi, Marco and Foumashi, Mohammad Mozaffari and Parenti-Castelli, Vincenzo},
booktitle = {Int. Conf. on Rehabilitation Robotics},
month = {Jun},
pages = {1--7},
publisher = {IEEE},
title = {{Preliminary results of BRAVO project: Brain computer interfaces for Robotic enhanced Action in Visuo-motOr tasks}},
year = {2011}
}
@article{Bogue2010,
author = {Bogue, Robert},
journal = {Industrial Robot},
keywords = {brain,computers,control technology,man machine interface,paper type technical paper,robotics},
number = {2},
pages = {126--132},
title = {{Brain-computer interfaces: control by thought}},
volume = {37},
year = {2010}
}
@article{Bong-Gun,
abstract = {This work presents that, only using non-invasively captured brain signals, a person can navigate an electric wheelchair with no serious training for a long term. Only two electrodes are set on the scalp non-invasively to detect a P300 EEG signal and a reference signal. A simple signal processing interprets the measured signals to decide a movement direction of the wheelchair. The whole devices are loaded on the wheelchair. No external system is required. The experimental results demonstrate the feasibility of the simple BCI processing to achieve reasonable performance.},
author = {Bong-Gun, Shin and Taesoo, Kim and Sungho, Jo},
journal = {Int. Conf. on Control Automation and Systems (ICCAS)},
pages = {2257--2260},
title = {{Non-invasive brain signal interface for a wheelchair navigation}},
}
@article{Castellini2009,
abstract = {One of the major problems when dealing with highly dexterous, active hand prostheses is their control by the patient wearing them. With the advances in mechatronics, building prosthetic hands with multiple active degrees of freedom is realisable, but actively controlling the position and especially the exerted force of each finger cannot yet be done naturally. This paper deals with advanced robotic hand control via surface electromyography. Building upon recent results, we show that machine learning, together with a simple downsampling algorithm, can be effectively used to control on-line, in real time, finger position as well as finger force of a highly dexterous robotic hand. The system determines the type of grasp a human subject is willing to use, and the required amount of force involved, with a high degree of accuracy. This represents a remarkable improvement with respect to the state-of-the-art of feed-forward control of dexterous mechanical hands, and opens up a scenario in which amputees will be able to control hand prostheses in a much finer way than it has so far been possible.},
author = {Castellini, Claudio and van der Smagt, Patrick},
journal = {Biological cybernetics},
keywords = {Algorithms,Artificial Intelligence,Artificial Limbs,Biomechanics,Electromyography,Electromyography: instrumentation,Electromyography: methods,Hand,Hand Strength,Humans,Neural Networks (Computer),Prosthesis Design,Robotics},
month = jan,
number = {1},
pages = {35--47},
title = {{Surface EMG in advanced hand prosthetics.}},
volume = {100},
year = {2009}
}
@inproceedings{Chen2009,
abstract = {Brain-computer interface (BCI) provides a new communication pathway for patients with neurological disorders who may not make voluntary muscle contraction. A potential BCI application is that patients may control a neuro-prosthetic robot directly from their brain so that they can achieve virtual interaction with environment. Therefore, a BCI supports multi-dimensional control is highly demanded for a multi-dimensional robot. We hypothesized that human intentions to move his right, left hand, leg and tongue can be detected by the somatotopic spatial activation patterns from single-trial MEG signal. Under reliable detection, human can intentionally control a two-dimensional robotic motion; right, left, up and down. The hypothesis was tested offline; the classification was performed on beta band activation (15-30 Hz) of SAM virtual channels. Cross-validation results using linear discrimination provided high detection accuracy (70-90\%) when considering a random level of 25\%. We demonstrated that noninvasive BCI methods may support reliable multi-dimensional control of neuro-prosthetic robotics.},
author = {Chen, Xuedong and Bai, Ou},
booktitle = {Int. Conf. on Complex Medical Engineering},
month = {Apr},
pages = {1--5},
title = {{Towards multi-dimensional robotic control via noninvasive brain-computer interface}},
year = {2009}
}
@article{ChuehM.AuYeungY.L.LeiK.-P.&Joshi2008,
author = {Chueh, M. and {Au Yeung}, Y.L. and Lei, K.-P. and Joshi, S.S.},
journal = {IEEE Transactions on Industrial Electronics},
number = {8},
pages = {3124--3132},
title = {{Following controller for autonomous mobile robots using behavioral cues}},
volume = {55},
year = {2008}
}
@article{Cincotti2007,
abstract = {In this pilot study, a system that allows disabled persons to improve or recover their mobility and communication within the surrounding environment was implemented and validated. The system is based on a software controller that offers to the user a communication interface that is matched with the individual's residual motor abilities. Fourteen patients with severe motor disabilities due to progressive neurodegenerative disorders were trained to use the system prototype under a rehabilitation program. All users utilized regular assistive control options (e.g., microswitches or head trackers) while four patients learned to operate the system by means of a non-invasive EEG-based Brain-Computer Interface, based on the subjects' voluntary modulations of EEG sensorimotor rhythms recorded on the scalp.},
author = {Cincotti, Febo and Aloise, Fabio and Bufalari, Simona and Schalk, Gerwin and Oriolo, Giuseppe and Cherubini, Andrea and Davide, Fabrizio and Babiloni, Fabio and Marciani, Maria Grazia and Mattia, Donatella},
journal = {Proc. Int. Conf. of the IEEE Engineering in Medicine and Biology Society.},
keywords = {Brain,Communication Aids for Disabled,Computer Systems,Humans,Neurodegenerative Diseases,Neurodegenerative Diseases: psychology,Neurodegenerative Diseases: rehabilitation,Quality of Life,Self-Help Devices,Software,User-Computer Interface},
month = jan,
pages = {2532--5},
title = {{Non-invasive brain-computer interface system to operate assistive devices.}},
volume = {2007},
year = {2007}
}

@article{Ciocarlie2008,
abstract = {In this paper we outline a grasp planning system designed to augment the cortical control of a prosthetic arm and hand. A key aspect of this system it the ability to combine online user input and autonomous planning to enable the execution of stable grasping tasks. While user input can ultimately be of any modality, the system is being designed to adapt to partial or noisy information obtained from grasp-related activity in the primate motor cortex. First, principal component analysis is applied to the observed kinematics of physiologic grasping to reduce the dimensionality of hand posture space and simplify the planning task for on-line use. The planner then accepts control input in this reduced-dimensionality space, and uses it as a seed for a hand posture optimization algorithm based on simulated annealing. We present two applications of this algorithm, using data collected from both primate and human subjects during grasping, to demonstrate its ability to synthesize stable grasps using partial control input in real or near-real time.},
annote = {PCA applied to observed kinematics of physiologic grasping to reduce dimensionalty of hand posture space.

        
High number of degrees of freedom of control are needed to successfully complete a grasping or manipulating task.

        
Taylor et al. enable a primate to directly control linear velocity through 3 DOFs in real time.  This control was achieved by measuring the activity of individual cortical neurons that correspond to the preferred directions.  

        
Velliste also demonstrated continuous cortical control of a robotic pincer.

        
While this approach is effective for transport and pinching.  The nature of dexterous grasping is different.
4-DOF manipulator whose main function is grasping to bring the hand to a certain point in 3-D space.  

        
In this setting even a single degree of freedom can be helpful.  Grasp quality function becomes Q = f(a,w) 

        

        

        
In our approach we use eigengrasps.  Santello et al. have showed that two such basis vectors can account for more than 80\%of the human hand grasp posture over 57 objects.

        
Efficient algorithm which operates in a 2 dimensional subspace to synthesize grasps.  Operaters on to produce pregrasms which NEARLY conform to objects.

        

        

        
Functionality and interactivity - find a stable grasp fast
Adjustable cortical/ computer control - Operator control vs synthetic behavior should be directly adjustable, allowing both learning and adaptation.

        
Biomimetic synthesis: in the absense of complete control, grasps will be created such that automatically controlled parameters will resembler observed physiologic behavior as possible.

        

        

        

        
As a prosthetic device, any actuated device is good enough.  In contrast, the human hand is 24-DOF manipulator which is designed to conform to the surface of an object.  
The activity of some motor neurons is correlated with finger movements, or joint angles, however 24 degrees of freedom is unlikely to be recovered.  Furthermore, the robotic hand generally has different kinematics.  Translating actuation of robot with a particular non-physiologic kinematic configuration could be difficult

        

        
Grasp planning system should incorporate some criteria in order to be appropriate for neural prosthetic control.  

        

        

        

      },
author = {Ciocarlie, Matei T. and Clanton, Samuel T. and Spalding, M. Chance and Allen, Peter K.},
journal = {Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems},
pages = {2271--2276},
publisher = {IEEE},
title = {{Biomimetic grasp planning for cortical control of a robotic hand}},
year = {2008}
}
@article{Cipriani2008,
abstract = {An anthropomorphic underactuated prosthetic hand, endowed with position and force sensors and controlled by means of myoelectric commands, is used to perform experiments of hierarchical shared control. Three different hierarchical control strategies combined with a vibrotactile feedback system have been developed and tested by able-bodied subjects through grasping tasks used in activities of daily living (ADLs). The first goal is to find a good tradeoff between good grasping capabilities and low attention required by the user to complete grasping tasks, without addressing advanced algorithm for electromyographic processing. The second goal is to understand whether a vibrotactile feedback system is subjectively or objectively useful and how it changes users' performance. Experiments showed that users were able to successfully operate the device in the three control strategies, and that the grasp success increased with more interactive control. Practice has proven that when too much effort is required, subjects do not do their best, preferring, instead, a less-interactive control strategy. Moreover, the experiments showed that when grasping tasks are performed under visual control, the enhanced proprioception offered by a vibrotactile system is practically not exploited. Nevertheless, in subjective opinion, feedback seems to be quite important.},
author = {Cipriani, Christian and Zaccone, F and Micera, Silvestro and Carrozza, Maria C.},
journal = {IEEE Transactions on Robotics},
month = feb,
number = {1},
pages = {170--184},
title = {{On the Shared Control of an EMG-Controlled Prosthetic Hand: Analysis of User Prosthesis Interaction}},
volume = {24},
year = {2008}
}
@phdthesis{Clanton2011,
abstract = {This thesis describes a brain-computer interface (BCI) system that was developed to allow direct cortical control of 7 active degrees of freedom in a robotic arm. Two monkeys with chronic microelectrode implants in their motor cortices were able to use the arm to complete an oriented grasping task under brain control. This BCI system was created as a clinical prototype to exhibit (1) simultaneous decoding of cortical signals for control of the 3-D translation, 3-D rotation, and 1-D ﬁnger aperture of a robotic arm and hand, (2) methods for constructing cortical signal decoding models based on only observation of a moving robot, (3) a generalized method for training subjects to use complex BCI prosthetic robots using a novel form of operator-machine shared control, and (4) integrated kinematic and force control of a brain-controlled prosthetic robot through a novel impedance-based robot controller. This dissertation describes each of these features individually, how their integration enriched BCI control, and results from the monkeys operating the resulting system},
author = {Clanton, Samuel T},
pages = {199},
school = {Carnegie Mellon University},
title = {{Brain-Computer Interface Control of an Anthropomorphic Robotic Arm}},
year = {2011}
}
@article{DeLuca2001,
author = {{De Luca}, C.J.},
journal = {IEEE Transactions on Biomedical Engineering},
number = {7},
pages = {745--753},
title = {{Physiology and Mathematics of Myoelectric Signals}},
volume = {48},
year = {2001}
}
@incollection{DennisJ.Mcfarland2010,
abstract = {A brain–computer interface (BCI) uses signals recorded from the brain to convey the user's intent. BCIs can be used for communication or can provide control signals for robotic and prosthetic devices. In studies to date, both invasive and noninvasive recording methods have proved effective and have reached comparable levels of performance. The major challenge for both invasive and noninvasive BCI-based robotic control is to achieve the speed, accuracy, and reliability necessary for real-world applications. These requirements vary with the specific application and with the control strategy employed.},
author = {{Dennis J. Mcfarland}, Jonathan R. Wolpaw},
chapter = {4},
edition = {79},
pages = {169--187},
series = {Advances in Computers},
title = {{Brain–Computer Interfaces for the Operation of Robotic and Prosthetic Devices}},
volume = {79},
year = {2010}
}
@article{GanjiF.JoshiS.S.&Bayard2006,
author = {Ganji, F. and Joshi, S.S. and Bayard, D.S.},
journal = {Journal of Guidance, Control, and Dynamics},
number = {3},
pages = {714--724},
title = {{Adaptive formation control for rovers traveling over unknown terrains}},
volume = {29},
year = {2006}
}
@article{Gomez-Gil2011,
author = {Gomez-Gil, Jaime and San-Jose-Gonzalez, Israel and Nicolas-Alonso, Luis Fernando and Alonso-Garcia, Sergio},
title = {{Steering a Tractor by Means of an EMG-Based Human-Machine Interface}},
journal = {Sensors},
number = {7},
volume = {11},
year = {2011}
}
@article{Harmon2005,
abstract = {A Simulink model, a propulsion energy optimization algorithm, and a CMAC controller were developed for a small parallel hybrid-electric unmanned aerial vehicle (UAV). The hybrid-electric UAV is intended for military, homeland security, and disaster-monitoring missions involving intelligence, surveillance, and reconnaissance (ISR). The Simulink model is a forward-facing simulation program used to test different control strategies. The flexible energy optimization algorithm for the propulsion system allows relative importance to be assigned between the use of gasoline, electricity, and recharging. A cerebellar model arithmetic computer (CMAC) neural network approximates the energy optimization results and is used to control the parallel hybrid-electric propulsion system. The hybrid-electric UAV with the CMAC controller uses 67.3\% less energy than a two-stroke gasoline-powered UAV during a 1-h ISR mission and 37.8\% less energy during a longer 3-h ISR mission.},
author = {Harmon, Frederick G and Frank, Andrew A and Joshi, Sanjay S},
institution = {Department of Mechanical and Aeronautical Engineering, University of California-Davis, Davis, CA 95616, USA. fgharmon@ucdavis.edu},
journal = {Neural Networks},
number = {5-6},
pages = {772--780},
title = {{The control of a parallel hybrid-electric propulsion system for a small unmanned aerial vehicle using a CMAC neural network.}},
volume = {18},
year = {2005}
}
@inproceedings{Hazrati2008,
abstract = {This paper presents a new EEG-based Brain-Computer Interface (BCI) for on-line controlling the sequence of hand grasping and holding in a virtual reality environment. The goal of this research is to develop an interaction technique that will allow the BCI to be effective in real-world scenarios for hand grasp control. Moreover, for consistency of man-machine interface, it is desirable the intended movement to be what the subject imagines. For this purpose, we developed an on-line BCI which was based on the classification of EEG associated with imagination of the movement of hand grasping and resting state. A classifier based on probabilistic neural network (PNN) was introduced for classifying the EEG. The PNN is a feedforward neural network that realizes the Bayes decision discriminant function by estimating probability density function using mixtures of Gaussian kernels. Two types of classification schemes were considered here for on-line hand control: adaptive and static. In contrast to static classification, the adaptive classifier was continuously updated on-line during recording. The experimental evaluation on six subjects on different days demonstrated that by using the static scheme, a classification accuracy as high as the rate obtained by the adaptive scheme can be achieved. At the best case, an average classification accuracy of 93.0\% and 85.8\% was obtained using adaptive and static scheme, respectively. The results obtained from more than 1500 trials on six subjects showed that interactive virtual reality environment can be used as an effective tool for subject training in BCI.},
author = {Hazrati, Mehrnaz K and Erfanian, Abbas},
booktitle = {Proc. Int. Conf. of the Engineering in Medicine and Biology Society.},
month = jan,
pages = {1009--12},
title = {{An on-line BCI for control of hand grasp sequence and holding using adaptive probabilistic neural network.}},
volume = {2008},
year = {2008}
}
@article{Heger2011,
author = {Heger, Dominic and Putze, Felix and Schultz, Tanja},
journal = {International Journal of Social Robotics},
month = sep,
number = {September},
title = {{An EEG Adaptive Information System for an Empathic Robot}},
year = {2011}
}
@inproceedings{Ho2011,
abstract = {An exoskeleton hand robotic training device is specially designed for persons after stroke to provide training on their impaired hand by using an exoskeleton robotic hand which is actively driven by their own muscle signals. It detects the stroke person's intention using his/her surface electromyography (EMG) signals from the hemiplegic side and assists in hand opening or hand closing functional tasks. The robotic system is made up of an embedded controller and a robotic hand module which can be adjusted to fit for different finger length. Eight chronic stroke subjects had been recruited to evaluate the effects of this device. The preliminary results showed significant improvement in hand functions (ARAT) and upper limb functions (FMA) after 20 sessions of robot-assisted hand functions task training. With the use of this light and portable robotic device, stroke patients can now practice more easily for the opening and closing of their hands at their own will, and handle functional daily living tasks at ease. A video is included together with this paper to give a demonstration of the hand robotic system on chronic stroke subjects and it will be presented in the conference.},
author = {Ho, N. S. K. and Tong, K. Y. and Hu, X. L. and Fung, K. L. and Wei, X. J. and Rong, W. and Susanto, E. A.},
booktitle = {Int. Conf. on Rehabilitation Robotics},
month = jun,
pages = {1--5},
publisher = {IEEE},
title = {{An EMG-driven exoskeleton hand robotic training device on chronic stroke subjects: Task training system for stroke rehabilitation}},
year = {2011}
}
@article{Hong-liu2010,
author = {Hong-liu, Yu and Pan-pan, Li and Jia-hua, Hu},
journal = {Technology},
keywords = {control,development,signal sources,upper prosthetic limb},
month = jul,
pages = {57},
title = {{Development of upper limb prosthesis technology}},
year = {2010}
}
@article{Horki2011,
abstract = {A Brain-Computer Interface (BCI) is a device that transforms brain signals, which are intentionally modulated by a user, into control commands. BCIs based on motor imagery (MI) and steady-state visual evoked potentials (SSVEP) can partially restore motor control in spinal cord injured patients. To determine whether these BCIs can be combined for grasp and elbow function control independently, we investigated a control method where the beta rebound after brisk feet MI is used to control the grasp function, and a two-class SSVEP-BCI the elbow function of a 2 degrees-of-freedom artificial upper limb. Subjective preferences for the BCI control were assessed with a questionnaire. The results of the initial evaluation of the system suggests that this is feasible.},
author = {Horki, Petar and Solis-Escalante, Teodoro and Neuper, Christa and M\"{u}ller-Putz, Gernot},
journal = {Medical \& Biological Engineering \& Computing},
keywords = {bci,computer interface,potential,ssvep,steady-state visual evoked,\'{a},\'{a} brain},
month = may,
number = {5},
pages = {567--77},
title = {{Combined motor imagery and SSVEP based BCI control of a 2 DoF artificial upper limb.}},
volume = {49},
year = {2011}
}
@article{Horki2011a,
abstract = {A Brain-Computer Interface (BCI) is a device that transforms brain signals, which are intentionally modulated by a user, into control commands. BCIs based on motor imagery (MI) and steady-state visual evoked potentials (SSVEP) can partially restore motor control in spinal cord injured patients. To determine whether these BCIs can be combined for grasp and elbow function control independently, we investigated a control method where the beta rebound after brisk feet MI is used to control the grasp function, and a two-class SSVEP-BCI the elbow function of a 2 degrees-of-freedom artificial upper limb. Subjective preferences for the BCI control were assessed with a questionnaire. The results of the initial evaluation of the system suggests that this is feasible.},
author = {Horki, Petar and Solis-Escalante, Teodoro and Neuper, Christa and M\"{u}ller-Putz, Gernot},
journal = {Medical \& Biological Engineering \& Computing},
keywords = {Medicine},
month = may,
number = {5},
pages = {567--77},
title = {{Combined motor imagery and SSVEP based BCI control of a 2 DoF artificial upper limb.}},
volume = {49},
year = {2011}
}
@article{Joshi2006,
author = {Joshi, Sanjay S. and Guilhabert, Benoit},
journal = {Adaptive Behavior},
number = {1},
pages = {53--71},
title = {{Sequence-Learning Algorithm Based on Backward Chaining}},
volume = {14},
year = {2006}
}
@inproceedings{JoshiS.S.WexlerA.S.Perez-MaldonadoC.&Vernon2011,
address = {Cancun},
author = {{Joshi, Sanjay S.} and Wexler, Anthony S. and Perez-Maldonado, Claudia and Vernon, Scott},
booktitle = {Int. Conf. on Engineering in Medicine \& Biology},
title = {{Brain-Muscle-Computer Interface Using a Single Surface Electromyographic Signal: Initial Results}},
year = {2011}
}
@article{Kanajar2011,
author = {Kanajar, Pavan and Ranatunga, Isura and Rajruangrabin, Jartuwat and Popa, Dan O and Makedon, Fillia},
journal = {Neurology},
pages = {1--6},
title = {{Neptune : Assistive Robotic System for Children with Motor Impairments}},
year = {2011}
}
@article{Kim2006,
abstract = {Research on brain-machine interfaces (BMI's) is directed toward enabling paralyzed individuals to manipulate their environment through slave robots. Even for able-bodied individuals, using a robot to reach and grasp objects in unstructured environments can be a difficult telemanipulation task. Controlling the slave directly with neural signals instead of a hand-master adds further challenges, such as uncertainty about the intended trajectory coupled with a low update rate for the command signal. To address these challenges, a continuous shared control (CSC) paradigm is introduced for BMI where robot sensors produce reflex-like reactions to augment brain-controlled trajectories. To test the merits of this approach, CSC was implemented on a 3-degree-of-freedom robot with a gripper bearing three co-located range sensors. The robot was commanded to follow eighty-three reach-and-grasp trajectories estimated previously from the outputs of a population of neurons recorded from the brain of a monkey. Five different levels of sensor-based reflexes were tested. Weighting brain commands 70\% and sensor commands 30\% produced the best task performance, better than brain signals alone by more than seven-fold. Such a marked performance improvement in this test case suggests that some level of machine autonomy will be an important component of successful BMI systems in general.},
author = {Kim, Hyun K and Biggs, S James and Schloerb, David W and Carmena, Jose M and Lebedev, Mikhail A and Nicolelis, Miguel A L and Srinivasan, Mandayam a},
journal = {IEEE Transactions on Biomedical Engineering},
month = jun,
number = {6},
pages = {1164--73},
title = {{Continuous shared control for stabilizing reaching and grasping with brain-machine interfaces.}},
volume = {53},
year = {2006}
}
@article{Kim2009,
abstract = {Many patients suffer from the loss of motor skills, resulting from traumatic brain and spinal cord injuries, stroke, and many other disabling conditions. Thanks to technological advances in measuring and decoding the electrical activity of cortical neurons, brain-machine interfaces (BMI) have become a promising technology that can aid paralyzed individuals. In recent studies on BMI, robotic manipulators have demonstrated their potential as neuroprostheses. Restoring motor skills through robot manipulators controlled by brain signals may improve the quality of life of people with disability. This article reviews current robotic technologies that are relevant to BMI and suggests strategies that could improve the effectiveness of a brain-operated neuroprosthesis through robotics.},
author = {Kim, Hyun K and Park, Shinsuk and Srinivasan, Mandayam A},
journal = {Human Movement Science},
month = apr,
number = {2},
pages = {191--203},
title = {{Developments in brain-machine interfaces from the perspective of robotics.}},
volume = {28},
year = {2009}
}
@article{Lee2009,
abstract = {Real-time functional MRI (rtfMRI) has been used as a basis for brain-computer interface (BCI) due to its ability to characterize region-specific brain activity in real-time. As an extension of BCI, we present an rtfMRI-based brain-machine interface (BMI) whereby 2-dimensional movement of a robotic arm was controlled by the regulation (and concurrent detection) of regional cortical activations in the primary motor areas. To do so, the subjects were engaged in the right- and/or left-hand motor imagery tasks. The blood oxygenation level dependent (BOLD) signal originating from the corresponding hand motor areas was then translated into horizontal or vertical robotic arm movement. The movement was broadcasted visually back to the subject as a feedback. We demonstrated that real-time control of the robotic arm only through the subjects' thought processes was possible using the rtfMRI-based BMI trials.},
author = {Lee, Jong-Hwan and Ryu, Jeongwon and Jolesz, Ferenc A and Cho, Zang-Hee and Yoo, Seung-Schik},
journal = {Neuroscience Letters},
month = jan,
number = {1},
pages = {1--6},
title = {{Brain-machine interface via real-time fMRI: preliminary study on thought-controlled robotic arm.}},
volume = {450},
year = {2009}
}
@article{Lin2010,
abstract = {Biomedical signal monitoring systems have rapidly advanced in recent years, propelled by significant advances in electronic and information technologies. Brain-computer interface (BCI) is one of the important research branches and has become a hot topic in the study of neural engineering, rehabilitation, and brain science. Traditionally, most BCI systems use bulky, wired laboratory-oriented sensing equipments to measure brain activity under well-controlled conditions within a confined space. Using bulky sensing equipments not only is uncomfortable and inconvenient for users, but also impedes their ability to perform routine tasks in daily operational environments. Furthermore, owing to large data volumes, signal processing of BCI systems is often performed off-line using high-end personal computers, hindering the applications of BCI in real-world environments. To be practical for routine use by unconstrained, freely-moving users, BCI systems must be noninvasive, nonintrusive, lightweight and capable of online signal processing. This work reviews recent online BCI systems, focusing especially on wearable, wireless and real-time systems.},
author = {Lin, Chin-Teng and Ko, Li-Wei and Chang, Meng-Hsiu and Duann, Jeng-Ren and Chen, Jing-Ying and Su, Tung-Ping and Jung, Tzyy-Ping},
journal = {Gerontology},
keywords = {Aged,Aging,Brain Diseases,Brain Diseases: rehabilitation,Communication Aids for Disabled,Electroencephalography,Electroencephalography: instrumentation,Electroencephalography: methods,Humans,Telemetry,Telemetry: instrumentation,Telemetry: methods,User-Computer Interface},
month = jan,
number = {1},
pages = {112--9},
title = {{Review of wireless and wearable electroencephalogram systems and brain-computer interfaces--a mini-review.}},
volume = {56},
year = {2010}
}
@techreport{M.BryanV.ThomasG.NicollL.Chang2011,
abstract = {Directing robots to perform remote tasks with human supervision has been a subject of considerable interest in the robotics community [1], [2], [3]. Humanoid robots in particular are often considered proxies or assistants to humans, performing tasks in real-world environments designed for humans. Recent advances in neuroscience and humanoid robotics have allowed initial demonstrations of brain-computer interfaces (BCIs) for controlling humanoid robots [4], [5], [6]. This is of particular interest since it could allow a severely paralyzed patient to use a robot as a proxy to perform a task. With such a system, a patient would be able to issue commands to the robot without the need of physical movement. This proposal is challenging due to the low throughput of the BCI and the high degrees-of-freedom of the robot. The BCI’s low signal-to-noise ratio means less useful information may be acquired during any given time window. At the same time, the high degrees-of-freedom of the robot means a larger amount of information is necessary for full control during any given time window. A BCI/robot system must therefore provide a high-level interface which summarizes over the information necessary for full control of the robot (e.g. presenting an interface for a grasping pipeline where the BCI user only selects an object to grasp). At the same time, it must balance this high-level summary with the flexibility to achieve the tasks desired by the BCI user. In this demonstration we present a BCI system for directing a PR2 robot’s actions. The interface has been adapted for two example scenarios that are representative of possible interaction scenarios desired by a user. In the first demonstration, the interface controls a grasping interaction with objects detected in a room. This task illustrates the sort of functionality a BCI could provide in order to aid in patient autonomy. The second demonstration provides a pointing interface for the user to interact with a remote player in gameplay. This task shows how a BCI and robot proxy could aid in human-tohuman social interactions. These are representative of two broad classes of robotic teleoperation applications. This work was supported by the National Science Foundation (0622252 \& 0930908), the Office of Naval Research (ONR) Cognitive Science Program, and the ICT Collaborative Project BrainAble (247447). This material is based upon work supported by the National Science Foundation under Grant \# 1019343 to the Computing Research Association for the CIFellows Project. Fig. 1. Example screen from graphical interface. The user monitors the robot’s state through a video feed on this screen. This screen also displays potential commands. In this case, it displays a list of objects to which the robot can point. In the first scenario, we allow the user to rotate the head to look for objects, then select an object for grasping. The PR2 uses point cloud data to identify objects and presents them to the BCI user as numbered objects via a graphical interface. Once the user selects an object, PR2 will then use a grasping routine to attempt to grasp the object. Second, we have the user play a “shell” game in interaction with a dealer. The dealer hides an object under one of three “shells” (cups), then mixes them around. The BCI user watches the mixing process and guesses under which shell the object can be found. Once the dealer signals they are done mixing, the BCI user controls the PR2 to point at a particular shell. (See Fig. 1)},
address = {San Francisco},
author = {{M. Bryan, V. Thomas, G. Nicoll, L. Chang}, J.R. Smith and R.P.N. Rao},
institution = {Iros 2011: The PR2 Workshop},
title = {{What You Think is What You Get: Brain-Controlled Interfacing for the PR2}},
year = {2011}
}
@inproceedings{Mandel2009,
author = {Mandel, Christian and Luth, Thorsten and Laue, Tim and Rofer, Thomas and Graser, Axel and Krieg-Bruckner, Bernd},
booktitle = {Proc. Int. Conf. on Intelligent Robots and Systems},
month = oct,
pages = {1118--1125},
publisher = {IEEE},
title = {{Navigating a smart wheelchair with a brain-computer interface interpreting steady-state visual evoked potentials}},
year = {2009}
}
@inproceedings{Matrone2011,
abstract = {In this paper a case study is introduced, which assesses the suitability of a newly conceived two-channel myoelectric controller for a multi-fingered hand prosthesis. A PCA-based approach, previously presented by the authors, has been employed to control in real-time an underactuated 16-degrees of freedom robotic hand. A volunteer able-bodied subject was enrolled in this case study to test the system, controlling the prosthesis by means of his forearm EMG signals collected by active surface electrodes and properly processed. Trials have shown that the subject was able to successfully operate the prosthetic hand while performing the three prehensile forms mostly used in daily living activities (i.e. power, precision and lateral grips) and stably grasping several different objects. The experiments demonstrate the possibility to develop a bio-inspired myoelectric hand prosthesis endowed with an intuitive and human-like control system. The validation of the PCA-based EMG controller will be carried on in the near future also with hand amputees.},
author = {Matrone, G. and Cipriani, C. and Carrozza, M. C. and Magenes, G.},
booktitle = {Proc. Int. Conf. on Neural Engineering},
month = apr,
pages = {554--557},
title = {{Two-channel real-time EMG control of a dexterous hand prosthesis}},
year = {2011}
}
@article{McFarland2010,
abstract = {Brain-computer interfaces (BCIs) can use brain signals from the scalp (EEG), the cortical surface (ECoG), or within the cortex to restore movement control to people who are paralyzed. Like muscle-based skills, BCIs' use requires activity-dependent adaptations in the brain that maintain stable relationships between the person's intent and the signals that convey it. This study shows that humans can learn over a series of training sessions to use EEG for three-dimensional control. The responsible EEG features are focused topographically on the scalp and spectrally in specific frequency bands. People acquire simultaneous control of three independent signals (one for each dimension) and reach targets in a virtual three-dimensional space. Such BCI control in humans has not been reported previously. The results suggest that with further development noninvasive EEG-based BCIs might control the complex movements of robotic arms or neuroprostheses.},
author = {McFarland, Dennis J and Sarnacki, William a and Wolpaw, Jonathan R},
journal = {Journal of Neural Engineering},
keywords = {Algorithms,Brain,Brain: physiology,Computer Peripherals,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Humans,Imagination,Male,Motion,Spinal Cord Injuries,Spinal Cord Injuries: physiopathology,Spinal Cord Injuries: rehabilitation,User-Computer Interface},
month = jun,
number = {3},
pages = {036007},
title = {{Electroencephalographic (EEG) control of three-dimensional movement.}},
volume = {7},
year = {2010}
}
@article{Millan2010,
abstract = {In recent years, new research has brought the field of electroencephalogram (EEG)-based brain-computer interfacing (BCI) out of its infancy and into a phase of relative maturity through many demonstrated prototypes such as brain-controlled wheelchairs, keyboards, and computer games. With this proof-of-concept phase in the past, the time is now ripe to focus on the development of practical BCI technologies that can be brought out of the lab and into real-world applications. In particular, we focus on the prospect of improving the lives of countless disabled individuals through a combination of BCI technology with existing assistive technologies (AT). In pursuit of more practical BCIs for use outside of the lab, in this paper, we identify four application areas where disabled individuals could greatly benefit from advancements in BCI technology, namely, "Communication and Control", "Motor Substitution", "Entertainment", and "Motor Recovery". We review the current state of the art and possible future developments, while discussing the main research issues in these four areas. In particular, we expect the most progress in the development of technologies such as hybrid BCI architectures, user-machine adaptation algorithms, the exploitation of users' mental states for BCI reliability and confidence measures, the incorporation of principles in human-computer interaction (HCI) to improve BCI usability, and the development of novel BCI technology including better EEG devices.},
author = {Mill\'{a}n, J D R and Rupp, R and M\"{u}ller-Putz, G R and Murray-Smith, R and Giugliemma, C and Tangermann, M and Vidaurre, C and Cincotti, F and K\"{u}bler, a and Leeb, R and Neuper, C and M\"{u}ller, K-R and Mattia, D},
journal = {Frontiers in Neuroscience},
keywords = {assistive technology,bci,communication and control,entertainment,motor recovery,motor substitution},
month = jan,
number = {September},
pages = {1--15},
title = {{Combining Brain-Computer Interfaces and Assistive Technologies: State-of-the-Art and Challenges.}},
volume = {4},
year = {2010}
}
@article{Muller-Putz2005,
abstract = {This case study demonstrates the coupling of an electroencephalogram (EEG)-based Brain-Computer Interface (BCI) with an implanted neuroprosthesis (Freehand system). Because the patient was available for only 3 days, the goal was to demonstrate the possibility of a patient gaining control over the motor imagery-based Graz BCI system within a very short training period. By applying himself to an organized and coordinated training procedure, the patient was able to generate distinctive EEG-patterns by the imagination of movements of his paralyzed left hand. These patterns consisted of power decreases in specific frequency bands that could be classified by the BCI. The output signal of the BCI emulated the shoulder joystick usually used, and by consecutive imaginations the patient was able to switch between different grasp phases of the lateral grasp that the Freehand system provided. By performing a part of the grasp-release test, the patient was able to move a simple object from one place to another. The results presented in this work give evidence that Brain-Computer Interfaces are an option for the control of neuroprostheses in patients with high spinal cord lesions. The fact that the user learned to control the BCI in a comparatively short time indicates that this method may also be an alternative approach for clinical purposes.},
author = {M\"{u}ller-Putz, Gernot R and Scherer, Reinhold and Pfurtscheller, Gert and Rupp, R\"{u}diger},
journal = {Neuroscience Letters},
keywords = {Adult,Brain,Brain: physiology,Electric Stimulation,Electrodes, Implanted,Electroencephalography,Electroencephalography: instrumentation,Foot,Foot: physiology,Hand,Hand Strength,Hand Strength: physiology,Hand: physiology,Humans,Imagination,Imagination: physiology,Male,Motor Skills,Movement,Movement: physiology,Prostheses and Implants,Quadriplegia,Quadriplegia: physiopathology,Refractory Period, Electrophysiological,Spinal Cord Injuries,Spinal Cord Injuries: therapy},
number = {1-2},
pages = {169--74},
title = {{EEG-based neuroprosthesis control: a step towards clinical practice.}},
volume = {382},
year = {2005}
}
@article{Pasqualotto2011,
author = {Pasqualotto, Emanuele and Federici, Stefano and Belardinelli, Marta Olivetti},
journal = {Disability and Rehabilitation: Assistive Technology},
keywords = {als,assistive technology,brain,computer interfaces,p300,sensorimotor rhythm,ssvep,vep},
month = oct,
pages = {1--15},
title = {{Toward functioning and usable brain–computer interfaces (BCIs): A literature review}},
year = {2011}
}
@article{Perez-Maldonado2010,
abstract = {In this study, human subjects achieve two-dimensional cursor-to-target control using the surface electromyogram (sEMG) from a single muscle site. The X-coordinate and the Y-coordinate of the computer cursor were simultaneously controlled by the active manipulation of power within two frequency bands of the sEMG power-spectrum. Success of the method depends on the sEMG frequency bandwidths and their midpoints. We acquired the sEMG signals at a single facial muscle site of four able-bodied subjects and trained them, by visual feedback, to control the position of the cursor. After training, all four subjects were able to simultaneously control the X and Y positions of the cursor to accurately and consistently hit three widely-separated targets on a computer screen. This technology has potential application in a wide variety of human-machine interfaces to assistive technologies.},
author = {Perez-Maldonado, Claudia and Wexler, Anthony S and Joshi, Sanjay S},
institution = {Department of Biomedical Engineering, University of California, Davis, CA 95616, USA.},
journal = {Trans. on Neural and Rehabilitation Systems Engineering},
number = {2},
title = {{Two-dimensional cursor-to-target control from single muscle site sEMG signals.}},
volume = {18},
year = {2010}
}
@article{Postelnicu2011,
author = {Postelnicu, Cristian-cezar and Talaba, Doru and Toma, Madalina-ioana},
journal = {Int. Fed. For Information Processing},
pages = {157--164},
title = {{Controlling a Robotic Arm by Brainwaves and Eye}},
year = {2011}
}
@inproceedings{Ranky2010,
abstract = {A BMI using Electroencephalography (EEG) input, known as the Emotiv EPOC was tested with an external robotic arm to determine if it was suitable for control of peripherals. Within 2 weeks of training, subjects maintained or improved axial control of the robot arm, and reduced their overall performance time. Although the EPOC\~{A}\^{A}¿ does require further testing and development, its adaptability to multiple software programs, users and peripherals allows it to serve both Virtual Rehabilitation and device control in the immediate future.},
address = {New York, NY},
author = {Ranky, G. N. and Adamovich, S.},
booktitle = {Proc. Northeast Bioengineering Conference (NEBEC)},
month = mar,
pages = {1--2},
title = {{Analysis of a commercial EEG device for the control of a robot arm}},
year = {2010}
}
@inproceedings{Reyes2011,
address = {Gainesville Fl.},
author = {Reyes, J.F. and Tosunoglu, S.},
booktitle = {Florida Conference on Recent Advances in Robotics},
number = {May},
title = {{An Overview of Brain-Computer Interface Technology Applications in Robotics}},
year = {2011}
}
@article{Rossini2010a,
abstract = {Combining non-invasive monitoring of action-related brain signals with the invasive recordings of the nerve motor output could provide robust natural and bidirectional multimodal Brain-Machine interfaces. One 26 years old, right-handed male who had suffered traumatic trans-radial amputation of the left arm was connected in a bidirectional way with a robotic hand prostheses. Cortical signals related with movement programming, execution, and feed-back were recorded by non-invasive scalp electrodes to detect high-level information (i.e. onset of movement intention), while the efferent neural activity containing the low-level commands towards the missing limb was recorded from the amputated nerves by multipolar intra-neural electrodes. The aim of this article is to report advanced experiences aiming to investigate whether information on "hand-related" activities can be decoded by the combined analysis of motor-related signals simultaneously gathered via intraneural electrodes implanted into the peripheral nervous system and scalp recorded electroencephalography signals to govern a dexterous hand prosthesis using the natural neural "pathway".},
author = {Rossini, Luca and Rossini, Paolo M},
journal = {Proc. Int. Conf. of the IEEE Engineering in Medicine and Biology Society.},
month = jan,
pages = {134--7},
title = {{Combining ENG and EEG integrated analysis for better sensitivity and specificity of neuroprosthesis operations.}},
volume = {2010},
year = {2010}
}
@article{Rossini2010,
abstract = {Combining non-invasive monitoring of action-related brain signals with the invasive recordings of the nerve motor output could provide robust natural and bidirectional multimodal Brain-Machine interfaces. One 26 years old, right-handed male who had suffered traumatic trans-radial amputation of the left arm was connected in a bidirectional way with a robotic hand prostheses. Cortical signals related with movement programming, execution, and feed-back were recorded by non-invasive scalp electrodes to detect high-level information (i.e. onset of movement intention), while the efferent neural activity containing the low-level commands towards the missing limb was recorded from the amputated nerves by multipolar intra-neural electrodes. The aim of this article is to report advanced experiences aiming to investigate whether information on "hand-related" activities can be decoded by the combined analysis of motor-related signals simultaneously gathered via intraneural electrodes implanted into the peripheral nervous system and scalp recorded electroencephalography signals to govern a dexterous hand prosthesis using the natural neural "pathway".},
author = {Rossini, Luca and Rossini, Paolo M},
journal = {Proc. Int. Conf. of the IEEE Engineering in Medicine and Biology Society.},
month = jan,
pages = {134--7},
title = {{Combining ENG and EEG integrated analysis for better sensitivity and specificity of neuroprosthesis operations.}},
volume = {2010},
year = {2010}
}
@article{Royer2011,
abstract = {A brain-computer interface (BCI) can be used to accomplish a task without requiring motor output. Two major control strategies used by BCIs during task completion are process control and goal selection. In process control, the user exerts continuous control and independently executes the given task. In goal selection, the user communicates their goal to the BCI and then receives assistance executing the task. A previous study has shown that goal selection is more accurate and faster in use. An unanswered question is, which control strategy is easier to learn? This study directly compares goal selection and process control while learning to use a sensorimotor rhythm-based BCI. Twenty young healthy human subjects were randomly assigned either to a goal selection or a process control-based paradigm for eight sessions. At the end of the study, the best user from each paradigm completed two additional sessions using all paradigms randomly mixed. The results of this study were that goal selection required a shorter training period for increased speed, accuracy, and information transfer over process control. These results held for the best subjects as well as in the general subject population. The demonstrated characteristics of goal selection make it a promising option to increase the utility of BCIs intended for both disabled and able-bodied users.},
author = {Royer, Audrey S and Rose, Minn L and He, Bin},
journal = {Journal of Neural Engineering},
month = jun,
number = {3},
pages = {036012},
title = {{Goal selection versus process control while learning to use a brain-computer interface.}},
volume = {8},
year = {2011}
}
@inproceedings{Sagawa2005,
abstract = {A control method of a robot manipulator using EMG (electromyogram) from human face is proposed. The robot has three-degree-of-freedom arm and an en effector on the tip of the robot. The amplitude of the EMG signal generated from masseter, which is the muscle of jaw, corresponds to the velocity of the robot hand. The difference of the EMG level between right and left masseter determines the direction of the movement of the hand. The open/close control of the robot hand is activated by detecting double clenches performed within 0.6 seconds. Optimal filtering is applied to the measured EMG to enable effortless robot task. Picking, transferring and placing of a brick object are performed and the effectiveness of the proposed method has been confirmed.},
author = {Sagawa, K. and Kimura,O.},
booktitle = {Proc. Int. Conf. on Manufacturing and Industrial Technologies},
language = {en},
month = dec,
number = {1},
title = {{Control of robot manipulator using EMG generated from face}},
volume = {6042},
year = {2005}
}
@incollection{Scherer2011a,
abstract = {The performance of non-invasive electroencephalogram-based (EEG) brain-computer interfacing (BCI) has improved significantly in recent years. However, remaining challenges include the non-stationarity and the low signal-to-noise ratio (SNR) of the EEG, which limit the bandwidth and hence the available applications. In this paper, we review ongoing research in our labs and introduce novel concepts and applications. First, we present an enhancement of the 3-class self-paced Graz-BCI that allows interaction with the massive multiplayer online role playing game World of Warcraft. Second, we report on the long-term stability and robustness of detection of oscillatory components modulated by distinct mental tasks. Third, we describe a scalable, adaptive learning framework, which allows users to teach the BCI new skills on-the-fly. Using this hierarchical BCI, we successfully train and control a humanoid robot in a virtual home environment.},
annote = {
        From Duplicate 1 ( 
        
          Non-invasive Brain-Computer Interfaces: Enhanced Gaming and Robotic Control
        
         - Scherer, Reinhold; Friedrich, E; Allison, Brendan )

        
        

        

        

      },
author = {Scherer, Reinhold and Friedrich, Elisabeth C. V. and Allison, Brendan and Pr\"{o}ll, Markus and Chung, Mike and Cheung, Willy and Rao, Rajesh P. N. and Neuper, Christa and Pr, Markus},
booktitle = {Advances in Computational Intelligence},
month = jun,
title = {{Non-invasive brain-computer interfaces: enhanced gaming and robotic control}},
volume = {6691},
year = {2011}
}
@article{Shenoy2008,
abstract = {This paper presents a two-part study investigating the use of forearm surface electromyographic (EMG) signals for real-time control of a robotic arm. In the first part of the study, we explore and extend current classification-based paradigms for myoelectric control to obtain high accuracy (92-98\%) on an eight-class offline classification problem, with up to 16 classifications/s. This offline study suggested that a high degree of control could be achieved with very little training time (under 10 min). The second part of this paper describes the design of an online control system for a robotic arm with 4 degrees of freedom. We evaluated the performance of the EMG-based real-time control system by comparing it with a keyboard-control baseline in a three-subject study for a variety of complex tasks.},
author = {Shenoy, Pradeep and Miller, Kai J and Crawford, Beau and Rao, Rajesh N},
journal = {IEEE Transactions on Biomedical Engineering},
month = mar,
number = {3},
pages = {1128--35},
title = {{Online electromyographic control of a robotic prosthesis.}},
volume = {55},
year = {2008}
}
@inproceedings{Tavella2010,
abstract = {In this paper we show how healthy subjects can operate a non-invasive asynchronous BCI for controlling a FES neuroprosthesis and manipulate objects to carry out daily tasks in ecological conditions. Both, experienced and novel subjects proved to be able to deliver mental commands with high accuracy and speed. Our neuroprosthetic approach relies on a natural interaction paradigm, where subjects delivers congruent MI commands (i.e., they imagining a movement of the same hand they control through FES). Furthermore, we have tested our approach in a common daily task such as handwriting, which requires the user to split his/her attention to multitask between BCI control, reaching, and the primary handwriting task itself. Interestingly, the very low number of erroneous trials illustrates how during the experiments subjects were able to deliver commands just when they intended to do so. Similarly, the subjects could perform actions while delivering, or preparing to deliver, mental commands.},
author = {Tavella, Michele and Leeb, Robert and Rupp, Rudiger and Millan, Jose Del R},
journal = {Proc. Int. Conf. of the IEEE Engineering in Medicine and Biology Society.},
month = jan,
pages = {126--9},
title = {{Towards natural non-invasive hand neuroprostheses for daily living.}},
volume = {2010},
year = {2010}
}
@article{Thobbi2010,
abstract = {This paper presents a platform for ‘Remote Presence' which enables a person to be present at a remote location through the embodiment of a humanoid robot. We specifically propose the use of a humanoid robot since it will endow human like capabilities for manipulating the remote environment. The numerous sensors available on the humanoid robot such as vision, microphones are essential to give feedback to the human controller about the remote environment. In addition to this, the humanoid has capabilities such as speech synthesis, obstacle avoidance, and ability to grasp objects which can be used to perform a wide array of tasks. To control the actions of the robot we propose the use of non-invasive Brain Computer Interface. The BCI enables the user to conveniently control the robot in the remote environment. The human user receives audio and video feedback from the robot on a personal media viewer such as video goggles. This would help the user to feel total immersion in the remote environment. This system could immensely benefit a variety of sectors such as military, medicine, disaster management etc. for carrying out dangerous or physically intensive tasks},
author = {Thobbi, A and Kadam, R and Sheng, W},
number = {1},
pages = {41--45},
title = {{Achieving Remote Presence using a Humanoid Robot Controlled by a Non-Invasive BCI Device}},
volume = {10},
year = {2010}
}

@article{Vernon2011,
abstract = {We report prototype development and testing of a new mobile-phone-based brain-muscle-computer interface for severely paralyzed persons, based on previous results from our group showing that humans may actively create specified power levels in two separate frequency bands of a single surface electromyography (sEMG) signal. EMG activity on the surface of a single face muscle site (auricularis superior) is recorded with a standard electrode. This analog electrical signal is imported into an Android-based mobile phone and digitized via an internal A/D converter. The digital signal is split, and then simultaneously filtered with two band-pass filters to extract total power within two separate frequency bands. The user-modulated power in each frequency band serves as two separate control channels for machine control. After signal processing, the Android phone sends commands to external devices via a Bluetooth interface. Users are trained to use the device via visually based operant conditioning, with simple cursor-to-target activities on the phone screen. The mobile-phone prototype interface is formally evaluated on a single advanced Spinal Muscle Atrophy subject, who has successfully used the interface in his home in evaluation trials and for remote control of a television. Development of this new device will not only guide future interface design for community use, but will also serve as an information technology bridge for in situ data collection to quantify human sEMG manipulation abilities for a relevant population.},
author = {Vernon, Scott and Joshi, Sanjay S},
journal = {IEEE Transactions on Information Technology},
number = {4},
pages = {531--538},
title = {{Brain-muscle-computer interface: mobile-phone prototype development and testing.}},
volume = {15},
year = {2011}
}
@article{Vernon2011a,
author = {Vernon, Scott and Joshi, Sanjay S},
journal = {Computer Engineering},
pages = {5188--5194},
title = {{Multidimensional Control Using a Mobile- Phone Based Brain-Muscle-Computer Interface}},
year = {2011}
}

@inproceedings{Vourvopoulos2011,
abstract = {This paper focuses on the research of human-robot interaction through tele-operation with the help of brain-computer interfaces (BCIs). To accomplish that, a working system has been created based on off-the-shelf components. The experimental prototype uses the basic movement operations and obstacle detection of a Lego Mindstroms NXT Robot. There are two versions of this prototype, taking readings from the users' brain electrical activity in real-time performance. The first version is made by using a Neurosky Mindset, and is based on the attention levels of the user as the robot accelerates or decelerates. The second version is using an Emotiv Epoc headset taking readings from 14 sensors, being able to control fully the robot.},
author = {Vourvopoulos, Athanasios and Liarokapis, Fotis},
booktitle = {Int. Conf on Games and Virtual Worlds for Serious Applications},
month = may,
pages = {140--143},
title = {{Brain-Controlled NXT Robot: Tele-operating a Robot through Brain Electrical Activity}},
year = {2011}
}
@article{Waytowich,
abstract = {A Brain-Computer Interface (BCI) is a system that allows individuals with severe neuromuscular disorders to communicate and control devices using their brain waves. It has been demonstrated that a non-invasive scalp-recorded ElectroEncephaloGraphy (EEG) based BCI paradigm can be used by a disabled individual for long-term, reliable control of a personal computer. This BCI paradigm allows users to select from a set of symbols presented in a flashing visual matrix by classifying the resulting evoked brain responses. The same BCI paradigm and techniques can be used in a straightforward implementation to generate high-level commands for controlling a robotic manipulator in three dimensions according to user intent. The robot application is envisioned to provide superior dimensional control over alternative BCI techniques, as well as provide a wider variety of practical functions for performing everyday tasks. This paper describes the early stages toward providing disabled individuals a new level of autonomy for performing everyday tasks, hence improving their quality of life. The objective of the initial experiment is to demonstrate that an EEG-based BCI can provide accurate and reliable high-level control of a robotic manipulator. A man-machine interface between the human brain and the robotic manipulator is developed and the early stages of insight into the practicality of a BCI operated assistive manipulation device are explored.},
author = {Waytowich, N. and Henderson, A. and Krusienski, D. and Cox, D.},
journal = {World Automation Congress (WAC)},
pages = {1--6},
title = {{Robot application of a brain computer interface to staubli TX40 robots - early stages}},
}
@article{Woczowski2010,
author = {Wołczowski, Andrzej and Kurzyński, Marek},
journal = {Expert Systems},
month = feb,
number = {1},
pages = {53--70},
title = {{Human-machine interface in bioprosthesis control using EMG signal classification}},
volume = {27},
year = {2010}
}
@article{Wolpaw2004,
abstract = {Brain-computer interfaces (BCIs) can provide communication and control to people who are totally paralyzed. BCIs can use noninvasive or invasive methods for recording the brain signals that convey the user's commands. Whereas noninvasive BCIs are already in use for simple applications, it has been widely assumed that only invasive BCIs, which use electrodes implanted in the brain, can provide multidimensional movement control of a robotic arm or a neuroprosthesis. We now show that a noninvasive BCI that uses scalp-recorded electroencephalographic activity and an adaptive algorithm can provide humans, including people with spinal cord injuries, with multidimensional point-to-point movement control that falls within the range of that reported with invasive methods in monkeys. In movement time, precision, and accuracy, the results are comparable to those with invasive BCIs. The adaptive algorithm used in this noninvasive BCI identifies and focuses on the electroencephalographic features that the person is best able to control and encourages further improvement in that control. The results suggest that people with severe motor disabilities could use brain signals to operate a robotic arm or a neuroprosthesis without needing to have electrodes implanted in their brains.},
author = {Wolpaw, Jonathan R and McFarland, Dennis J},
institution = {Laboratory of Nervous System Disorders, Wadsworth Center, New York State Department of Health and State University of New York, Albany, NY 12201-0509, USA. wolpaw@wadsworth.org},
journal = {Proc. of the National Academy of Sciences of the United States of America},
number = {51},
pages = {17849--17854},
title = {{Control of a two-dimensional movement signal by a noninvasive brain-computer interface in humans}},
volume = {101},
year = {2004}
}
@inproceedings{Yang2009a,
abstract = {The multi-DOF prosthetic hand's myocontrol needs to recognize more hand gestures (or motions) based on myoelectric signals. This paper presents a classification method, which is based on the support vector machine (SVM), to classify 19 different hand gesture modes through electromyographic (EMG) signals acquired from six surface myoelectric electrodes. All hand gestures are based on a 3-DOF configuration, which makes the hand perform like three-fingered. The training performance is very high within each test session, but the cross-session validation is typically low. Acceptable cross-session performance can be achieved by training with more sessions or fewer gesture modes. A fast rhythm muscle contraction is suggested, which can make the training samples more resourceful and improve the prediction accuracy comparing with a relative slow muscle contraction method. For many precise grasp tasks, it is beneficial to the prosthetic hand's myocontrol if we can efficiently extract the grasp force directly from EMG signals. Through grasping a JR3 6 dimension force/torque sensor, the force signal applying to the sensor can be recorded synchronously with myoelectric signals. This paper uses three methods, local weighted projection regression (LWPR), artificial neural network (ANN) and SVM, to find the best regression relationship between these two kinds of signals. It reveals that the SVM method is better than ANN and LWPR, especially in the case of cross-session validation. Also, the performance of grasping force estimation based on specific hand gestures is superior to the performance of grasping with random fingers.},
author = {Yang, Dapeng and Zhao, Jingdong and Gu, Yikun and Jiang, Li and Liu, Hong},
booktitle = {Int. Conf. on Intelligent Robots and Systems},
month = oct,
pages = {516--521},
publisher = {IEEE},
title = {{EMG pattern recognition and grasping force estimation: Improvement to the myocontrol of multi-DOF prosthetic hands}},
year = {2009}
}
@article{Yang2009,
abstract = {When developing a humanoid myo-control hand, not only the mechanical structure should be considered to afford a high dexterity, but also the myoelectric (electromyography, EMG) control capability should be taken into account to fully accomplish the actuation tasks. This paper presents a novel humanoid robotic myocontrol hand (AR hand III) which adopted an underactuated mechanism and a forearm myocontrol EMG method. The AR hand III has five fingers and 15 joints, and actuated by three embedded motors. Underactuation can be found within each finger and between the rest three fingers (the middle finger, the ring finger and the little finger) when the hand is grasping objects. For the EMG control, two specific methods are proposed: the three-fingered hand gesture configuration of the AR hand III and a pattern classification method of EMG signals based on a statistical learning algorithm – Support Vector Machine (SVM). Eighteen active hand gestures of a testee are recognized effectively, which can be directly mapped into the motions of AR hand III. An on-line EMG control scheme is established based on two different decision functions: one is for the discrimination between the idle and active modes, the other is for the recognition of the active modes. As a result, the AR hand III can swiftly follow the gesture instructions of the testee with a time delay less than 100 ms.},
author = {Yang, Da-peng and Zhao, Jing-dong and Gu, Yi-kun and Wang, Xin-qing and Li, Nan and Jiang, Li and Liu, Hong and Huang, Hai and Zhao, Da-wei},
journal = {Journal of Bionic Engineering},
keywords = {distal emg,emg control,humanoid hand,support vector machine,underactuated mechanism},
mendeley-tags = {distal emg},
month = sep,
number = {3},
pages = {255--263},
title = {{An Anthropomorphic Robot Hand Developed Based on Underactuated Mechanism and Controlled by EMG Signals}},
volume = {6},
year = {2009}
}
@article{Zecca2002,
abstract = {The human hand is a complex system, with a large number of degrees of freedom (DoFs), sensors embedded in its structure, actuators and tendons, and a complex hierarchical control. Despite this complexity, the efforts required to the user to carry out the different movements is quite small (albeit after an appropriate and lengthy training). On the contray, prosthetic hands are just a pale replication of the natural hand, with significantly reduced grasping capabilities and no sensory information delivered back to the user. Several attempts have been carried out to develop multifunctional prosthetic devices controlled by electromyographic (EMG) signals (myoelectric hands), harness (kinematic hands), dimensional changes in residual muscles, and so forth, but none ofthese methods permits the \&quot;natural\&quot; control of more than two DoFs. This article presents a review of the traditional methods used to control artificial hands by means of EMG signal, in both the clinical and research contexts, and introduces what could be the future developments in the control strategy of these devices.},
author = {Zecca, M and Micera, S and Carrozza, M C and Dario, P},
journal = {Critical Reviews in Biomedical Engineering},
number = {4-6},
pages = {459--485},
publisher = {Begell House},
title = {{Control of multifunctional prosthetic hands by processing the electromyographic signal}},
volume = {30},
year = {2002}
}
@article{Zhao2009,
abstract = {Brain computer interface (BCI) aims at creating new communication channels without depending on brain’s normal output channels of peripheral nerves and muscles. However, natural and sophisticated interactions manner between brain and computer still remain challenging. In this paper, we investigate how the duration of event-related desynchronization/synchronization (ERD/ERS) caused by motor imagery (MI) can be modulated and used as an additional control parameter beyond simple binary decisions. Furthermore, using the non-time-locked properties of sustained (de)synchronization, we have developed an asynchronous BCI system for driving a car in 3D virtual reality environment (VRE) based on cumulative incremental control strategy. The extensive real time experiments confirmed that our new approach is able to drive smoothly a virtual car within challenging VRE only by the MI tasks without involving any muscular activities.},
author = {Zhao, QiBin and Zhang, LiQing and Cichocki, Andrzej},
journal = {Chinese Science Bulletin},
keywords = {Life Sciences},
month = jan,
number = {1},
pages = {78--87},
title = {{EEG-based asynchronous BCI control of a car in 3D virtual reality environments}},
volume = {54},
year = {2009}
}
@article{,
journal = {Frontiers in  Neuroprosthetics},
title = {{Frontiers: First Steps Toward a Motor Imagery Based Stroke BCI: New Strategy to Set up a Classifier}},
volume = {5}
}
@article{faceemg,
keywords = {Robot control,electromyogram,experiment,hands free control,masseter},
title = {{Robot manipulator control using EMG generated from a face}},
}
@misc{Emotiv,
keywords = {eeg,eeg system,electroencephalography,emotiv},
title = {{Emotiv EEG System}},
}